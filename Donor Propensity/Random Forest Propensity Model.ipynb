{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donor Propensity Model\n",
    "\n",
    "This notebook uses a Random Forest Classifier to find individuals who have a high potential to donate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, average_precision_score, precision_recall_curve\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline           # works with imbalanced‑learn\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_df = pd.read_csv(r\"C:\\Users\\maxwell.bicking\\donation_data_syn.csv\")\n",
    "\n",
    "#import median income by zip code data from Census Bureau\n",
    "census_df = pd.read_csv(r\"C:\\Users\\maxwell.bicking\\data-science-portfolio\\Donor Propensity\\Median Income by ZIP.csv\")\n",
    "\n",
    "census_df['ZIP'] = census_df['Geographic Area Name'].str.strip().str[-5:] #add zip column to join to contact table\n",
    "\n",
    "df = contacts_df.merge(\n",
    "    census_df[['ZIP', 'Median Income']],\n",
    "    left_on='ZIP_CODE',\n",
    "    right_on='ZIP',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df = df.drop(columns=['ZIP', 'CHURNED', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>EMAIL_OPT_OUT</th>\n",
       "      <th>CALL_OPT_OUT</th>\n",
       "      <th>DAYS_SINCE_CREATED</th>\n",
       "      <th>DAYS_SINCE_MODIFIED</th>\n",
       "      <th>DAYS_SINCE_LAST_ACTIVITY</th>\n",
       "      <th>HOME_CALL_OPT_OUT</th>\n",
       "      <th>MOBILE_CALL_OPT_OUT</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_DONATION_AMOUNT</th>\n",
       "      <th>TOTAL_DONATIONS</th>\n",
       "      <th>TOTAL_DONATION_AMOUNT_LY</th>\n",
       "      <th>TOTAL_DONATIONS_LY</th>\n",
       "      <th>ASSOCIATED_WITH_MEMBERSHIP</th>\n",
       "      <th>TITLE_CHANGE</th>\n",
       "      <th>PUSHED</th>\n",
       "      <th>CHURNED</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>Median Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2314</td>\n",
       "      <td>54</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>41.70</td>\n",
       "      <td>3</td>\n",
       "      <td>4.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92130</td>\n",
       "      <td>201731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2326</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2381</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21201</td>\n",
       "      <td>44722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>665</td>\n",
       "      <td>57</td>\n",
       "      <td>714.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33612</td>\n",
       "      <td>43919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>27</td>\n",
       "      <td>281.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46202</td>\n",
       "      <td>61082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>United States</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2301</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2312</td>\n",
       "      <td>57</td>\n",
       "      <td>666.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60612</td>\n",
       "      <td>60457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2025</td>\n",
       "      <td>50</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92115</td>\n",
       "      <td>75178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2333</td>\n",
       "      <td>40</td>\n",
       "      <td>196.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92130</td>\n",
       "      <td>201731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2239</td>\n",
       "      <td>31</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30322</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        COUNTRY   AGE  EMAIL_OPT_OUT  CALL_OPT_OUT  \\\n",
       "0           0  United States   NaN           True         False   \n",
       "1           1  United States   NaN           True         False   \n",
       "2           2  United States   NaN           True         False   \n",
       "3           3  United States   NaN           True         False   \n",
       "4           4  United States   NaN           True         False   \n",
       "5           5  United States  30.0           True         False   \n",
       "6           6            NaN   NaN           True         False   \n",
       "7           7  United States   NaN           True         False   \n",
       "8           8  United States   NaN           True         False   \n",
       "9           9  United States   NaN           True         False   \n",
       "\n",
       "   DAYS_SINCE_CREATED  DAYS_SINCE_MODIFIED  DAYS_SINCE_LAST_ACTIVITY  \\\n",
       "0                2314                   54                    1331.0   \n",
       "1                2326                   34                       NaN   \n",
       "2                2381                   96                       NaN   \n",
       "3                 665                   57                     714.0   \n",
       "4                2020                   27                     281.0   \n",
       "5                2301                   36                       NaN   \n",
       "6                2312                   57                     666.0   \n",
       "7                2025                   50                    1238.0   \n",
       "8                2333                   40                     196.0   \n",
       "9                2239                   31                    1272.0   \n",
       "\n",
       "   HOME_CALL_OPT_OUT  MOBILE_CALL_OPT_OUT  ...  TOTAL_DONATION_AMOUNT  \\\n",
       "0              False                False  ...                  41.70   \n",
       "1              False                False  ...                   0.03   \n",
       "2              False                False  ...                   3.22   \n",
       "3              False                False  ...                   0.00   \n",
       "4              False                False  ...                   0.00   \n",
       "5              False                False  ...                   0.00   \n",
       "6              False                False  ...                   0.00   \n",
       "7              False                False  ...                   0.05   \n",
       "8              False                False  ...                   0.00   \n",
       "9              False                False  ...                   0.00   \n",
       "\n",
       "   TOTAL_DONATIONS  TOTAL_DONATION_AMOUNT_LY  TOTAL_DONATIONS_LY  \\\n",
       "0                3                      4.15                   1   \n",
       "1                1                      1.28                   1   \n",
       "2                2                      3.80                   1   \n",
       "3                0                      0.28                   1   \n",
       "4                0                      0.00                   1   \n",
       "5                1                      0.00                   1   \n",
       "6                1                      0.01                   1   \n",
       "7                1                      0.00                   1   \n",
       "8                0                      4.26                   1   \n",
       "9                1                      0.00                   1   \n",
       "\n",
       "   ASSOCIATED_WITH_MEMBERSHIP TITLE_CHANGE PUSHED  CHURNED ZIP_CODE  \\\n",
       "0                           0            0      0        0    92130   \n",
       "1                           0            0      0        0    27157   \n",
       "2                           0            0      1        0    21201   \n",
       "3                           1            0      0        0    33612   \n",
       "4                           0            0      0        0    46202   \n",
       "5                           0            0      0        0    40536   \n",
       "6                           0            0      0        0    60612   \n",
       "7                           0            0      0        0    92115   \n",
       "8                           0            0      0        1    92130   \n",
       "9                           0            1      0        0    30322   \n",
       "\n",
       "  Median Income  \n",
       "0        201731  \n",
       "1           NaN  \n",
       "2         44722  \n",
       "3         43919  \n",
       "4         61082  \n",
       "5           NaN  \n",
       "6         60457  \n",
       "7         75178  \n",
       "8        201731  \n",
       "9           NaN  \n",
       "\n",
       "[10 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_cols = [\n",
    "    \"GENDER\", \"RACE\", \"COUNTRY\", \"ZIP_CODE\",\n",
    "    \"INCOME_LEVEL\", \"INSTITUTION_TYPE\", \"PRIMARY_RESEARCH_AREA\",\n",
    "    \"HIGHEST_DEGREE\", \"POLITICAL_PARTY\", \"Median Income\"\n",
    "]\n",
    "\n",
    "nonmember_cols = [\"MEMBER_TYPE\", \"MEMBERSHIP_STATUS\"]\n",
    "\n",
    "# Replace NaNs\n",
    "df[unknown_cols]   = df[unknown_cols].fillna(\"Unknown\")\n",
    "df[nonmember_cols] = df[nonmember_cols].fillna(\"Nonmember\")\n",
    "\n",
    "df['DONATED_LY_FLAG'] = (df['TOTAL_DONATIONS_LY'].fillna(0) > 0).astype(int)\n",
    "\n",
    "df['IS_TOP_DONOR'] = (df['TOTAL_DONATION_AMOUNT'] > 500).fillna(0).astype(int)\n",
    "\n",
    "df['NET_WORTH_QUARTILE'] = pd.qcut(df['NET_WORTH'], q=4, labels=[1, 2, 3, 4])\n",
    "df['NET_WORTH_QUARTILE'] = df['NET_WORTH_QUARTILE'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IS_TOP_DONOR\n",
       "0    85185\n",
       "1      186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IS_TOP_DONOR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric columns: ['AGE', 'DAYS_SINCE_CREATED', 'DAYS_SINCE_MODIFIED', 'DAYS_SINCE_LAST_ACTIVITY', 'DAYS_SINCE_JOINED', 'NET_WORTH', 'DAYS_SINCE_LAST_EVENT', 'TOTAL_MEETING_PAID_AMOUNT', 'TOTAL_NUMBER_OF_EVENTS_ATTENDED', 'TOTAL_MEETING_PAID_AMOUNT_LY', 'TOTAL_EVENTS_LY', 'LAST_DONATION_AMOUNT', 'DAYS_SINCE_LAST_DONATION', 'TOTAL_DONATION_AMOUNT', 'TOTAL_DONATIONS', 'TOTAL_DONATION_AMOUNT_LY', 'TOTAL_DONATIONS_LY', 'ASSOCIATED_WITH_MEMBERSHIP', 'TITLE_CHANGE', 'PUSHED', 'DONATED_LY_FLAG', 'NET_WORTH_QUARTILE']\n",
      "Categorical columns: ['COUNTRY', 'GENDER', 'INCOME_LEVEL', 'INSTITUTION_TYPE', 'MEMBER_TYPE', 'MEMBERSHIP_STATUS', 'PRIMARY_RESEARCH_AREA', 'RACE', 'HIGHEST_DEGREE', 'POLITICAL_PARTY', 'ZIP_CODE', 'Median Income']\n"
     ]
    }
   ],
   "source": [
    "#--- Identify Numeric and Categorical Columns ---\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"\\nNumeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxwell.bicking\\AppData\\Local\\Temp\\ipykernel_29448\\40960526.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(max, inplace = True)\n",
      "C:\\Users\\maxwell.bicking\\AppData\\Local\\Temp\\ipykernel_29448\\40960526.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['AGE'].fillna(median_age, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "max_cols = df[['DAYS_SINCE_LAST_ACTIVITY', 'DAYS_SINCE_JOINED', 'DAYS_SINCE_LAST_EVENT', 'DAYS_SINCE_LAST_DONATION']]\n",
    "\n",
    "# age: median\n",
    "\n",
    "for col in max_cols:\n",
    "    max = df[col].max()\n",
    "    df[col].fillna(max, inplace = True)\n",
    "\n",
    "median_age = df['AGE'].median()\n",
    "df['AGE'].fillna(median_age, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COUNTRY                            0\n",
       "AGE                                0\n",
       "EMAIL_OPT_OUT                      0\n",
       "CALL_OPT_OUT                       0\n",
       "DAYS_SINCE_CREATED                 0\n",
       "DAYS_SINCE_MODIFIED                0\n",
       "DAYS_SINCE_LAST_ACTIVITY           0\n",
       "HOME_CALL_OPT_OUT                  0\n",
       "MOBILE_CALL_OPT_OUT                0\n",
       "OTHER_CALL_OPT_OUT                 0\n",
       "PERSONAL_EMAIL_OPT_OUT             0\n",
       "WORK_CALL_OPT_OUT                  0\n",
       "WORK_EMAIL_OPT_OUT                 0\n",
       "DECEASED                           0\n",
       "GENDER                             0\n",
       "INCOME_LEVEL                       0\n",
       "DAYS_SINCE_JOINED                  0\n",
       "INSTITUTION_TYPE                   0\n",
       "MEMBER_TYPE                        0\n",
       "MEMBERSHIP_STATUS                  0\n",
       "PRIMARY_RESEARCH_AREA              0\n",
       "RACE                               0\n",
       "DO_NOT_EMAIL                       0\n",
       "PRE_POST_DOC                       0\n",
       "HIGHEST_DEGREE                     0\n",
       "NET_WORTH                          0\n",
       "SMALL_BUSINESS_OWNER               0\n",
       "IMPORTED_CAR_OWNER                 0\n",
       "MULTI_PROPERTY_OWNER               0\n",
       "NONPROFIT_BOARD_MEMBER             0\n",
       "RECENT_MORTGAGE                    0\n",
       "POLITICAL_DONOR                    0\n",
       "RECENT_DIVORCE                     0\n",
       "RECENT_MOVER                       0\n",
       "TOP_POLITICAL_DONOR                0\n",
       "LUXURY_CAR_OWNER                   0\n",
       "TRUST                              0\n",
       "PHILANTHROPIC_GIVER                0\n",
       "PLANE_OWNER                        0\n",
       "BOAT_OWNER                         0\n",
       "POLITICAL_PARTY                    0\n",
       "DAYS_SINCE_LAST_EVENT              0\n",
       "TOTAL_MEETING_PAID_AMOUNT          0\n",
       "TOTAL_NUMBER_OF_EVENTS_ATTENDED    0\n",
       "TOTAL_MEETING_PAID_AMOUNT_LY       0\n",
       "TOTAL_EVENTS_LY                    0\n",
       "LAST_DONATION_AMOUNT               0\n",
       "DAYS_SINCE_LAST_DONATION           0\n",
       "TOTAL_DONATION_AMOUNT              0\n",
       "TOTAL_DONATIONS                    0\n",
       "TOTAL_DONATION_AMOUNT_LY           0\n",
       "TOTAL_DONATIONS_LY                 0\n",
       "ASSOCIATED_WITH_MEMBERSHIP         0\n",
       "TITLE_CHANGE                       0\n",
       "PUSHED                             0\n",
       "ZIP_CODE                           0\n",
       "Median Income                      0\n",
       "DONATED_LY_FLAG                    0\n",
       "NET_WORTH_QUARTILE                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#Define the target column and determine feature columns.\\n#We predict \"top_donor\" (assumed to be 0/1 or similar).\\ntarget_column = \\'IS_TOP_DONOR\\'\\n\\n#Remove the target column from the list of features.\\n#We might choose to drop columns that are not predictive or have too many unique values (e.g., MAILING_ZIP_CODE)\\ndrop_columns = [\\'MAILING_ZIP_CODE\\']  #add others if needed\\n\\n#Separate features and target\\nX = df.drop(columns=[target_column] + drop_columns)\\ny = df[target_column]\\n\\n#Identify lists for categorical and numerical columns.\\ncategorical_cols = [\\n    \\'COUNTRY\\', \\'GENDER\\', \\'INCOME_LEVEL\\', \\'INSTITUTION_TYPE\\', \\n    \\'MEMBER_TYPE\\', \\'MEMBERSHIP_STATUS\\', \\'PRIMARY_RESEARCH_AREA\\',\\n    \\'RACE\\', \\'POLITICAL_PARTY\\', \\'HIGHEST_DEGREE\\', \\'Median Income\\'\\n]\\n\\n#The remaining columns (or explicitly defined ones) are numerical or boolean.\\nnumerical_cols = [col for col in X.columns if col not in categorical_cols]\\n\\n#If there are boolean columns in categorical_cols, they may be left as numerical.\\n#make sure data types are correct:\\nfor col in X.columns:\\n    if X[col].dtype == \\'bool\\':\\n        X[col] = X[col].astype(int)\\n\\n\\n# Fill missing values.\\n# For numerical features, we can fill with the median.\\n# For categorical features, fill with a constant such as \\'missing\\'.\\nfor col in numerical_cols:\\n    X[col].fillna(X[col].median(), inplace=True)\\nfor col in categorical_cols:\\n    X[col].fillna(\\'missing\\', inplace=True)\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the target column and determine feature columns.\n",
    "#We predict \"top_donor\" (assumed to be 0/1 or similar).\n",
    "target_column = \"IS_TOP_DONOR\"\n",
    "drop_columns = [\"ZIP_CODE\"]          # add more if needed\n",
    "leakage_cols = [\n",
    "    'TOTAL_DONATION_AMOUNT', 'MOST_RECENT_DONATION_AMOUNT',\n",
    "    'TOTAL_OPPORTUNITIES', 'TOTAL_AMOUNT_LAST_YEAR',\n",
    "    'TOTAL_OPPORTUNITIES_LAST_YEAR', 'DONATION_QUARTILE'\n",
    "]\n",
    "\n",
    "\n",
    "X = df.drop(columns=[target_column] + drop_columns + leakage_cols).copy()\n",
    "y = df[target_column]\n",
    "\n",
    "# --- 2. Identify column groups dynamically -----------------------------------\n",
    "# A. booleans → convert to numeric 0/1 so they behave like numerics\n",
    "bool_cols = X.select_dtypes(include=[\"bool\"]).columns\n",
    "X[bool_cols] = X[bool_cols].astype(int)\n",
    "\n",
    "# B. categorical (object or pandas \"category\" dtype)\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# C. numeric (everything else that is already number‑like)\n",
    "numerical_cols = X.select_dtypes(include=[\"number\"]).columns.difference(bool_cols).tolist()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Define the target column and determine feature columns.\n",
    "#We predict \"top_donor\" (assumed to be 0/1 or similar).\n",
    "target_column = 'IS_TOP_DONOR'\n",
    "\n",
    "#Remove the target column from the list of features.\n",
    "#We might choose to drop columns that are not predictive or have too many unique values (e.g., MAILING_ZIP_CODE)\n",
    "drop_columns = ['MAILING_ZIP_CODE']  #add others if needed\n",
    "\n",
    "#Separate features and target\n",
    "X = df.drop(columns=[target_column] + drop_columns)\n",
    "y = df[target_column]\n",
    "\n",
    "#Identify lists for categorical and numerical columns.\n",
    "categorical_cols = [\n",
    "    'COUNTRY', 'GENDER', 'INCOME_LEVEL', 'INSTITUTION_TYPE', \n",
    "    'MEMBER_TYPE', 'MEMBERSHIP_STATUS', 'PRIMARY_RESEARCH_AREA',\n",
    "    'RACE', 'POLITICAL_PARTY', 'HIGHEST_DEGREE', 'Median Income'\n",
    "]\n",
    "\n",
    "#The remaining columns (or explicitly defined ones) are numerical or boolean.\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "#If there are boolean columns in categorical_cols, they may be left as numerical.\n",
    "#make sure data types are correct:\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'bool':\n",
    "        X[col] = X[col].astype(int)\n",
    "\n",
    "\n",
    "# Fill missing values.\n",
    "# For numerical features, we can fill with the median.\n",
    "# For categorical features, fill with a constant such as 'missing'.\n",
    "for col in numerical_cols:\n",
    "    X[col].fillna(X[col].median(), inplace=True)\n",
    "for col in categorical_cols:\n",
    "    X[col].fillna('missing', inplace=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a ColumnTransformer that:\n",
    "# - One-hot encodes categorical columns.\n",
    "# - Scales numerical columns.\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Building and Training Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold = 0.820\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     17038\n",
      "           1       0.74      0.68      0.70        37\n",
      "\n",
      "    accuracy                           1.00     17075\n",
      "   macro avg       0.87      0.84      0.85     17075\n",
      "weighted avg       1.00      1.00      1.00     17075\n",
      "\n",
      "PR‑AUC: 0.8095137776522194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'model\\', clf)\\n])\\n\\npipe.fit(X_train, y_train)\\n\\n#Hyperparameter tuning via GridSearchCV.\\nparam_grid = {\\n    \\'classifier__n_estimators\\': [100, 200],\\n    \\'classifier__max_depth\\': [None, 10, 20],\\n    \\'classifier__min_samples_split\\': [2, 5]\\n}\\n\\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\\'roc_auc\\', n_jobs=-1)\\ngrid_search.fit(X_train, y_train)\\n\\nprint(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\\nprint(\"Best ROC-AUC score from GridSearchCV:\", grid_search.best_score_)\\n\\n#Use the best estimator for evaluation\\nmodel = grid_search.best_estimator_\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split Data into Training and Test Sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp)\n",
    "\n",
    "# 3.  Balanced forest + pipeline\n",
    "clf = BalancedRandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    random_state=42,\n",
    "    sampling_strategy='auto')       # down‑samples majority each tree\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', clf)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 4.  Pick threshold on validation set\n",
    "val_proba = pipe.predict_proba(X_val)[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, val_proba)\n",
    "f1 = 2*precision*recall/(precision+recall+1e-9)\n",
    "best_thresh = thresholds[f1.argmax()]\n",
    "\n",
    "print(f\"Chosen threshold = {best_thresh:0.3f}\")\n",
    "\n",
    "# 5.  Final test metrics\n",
    "test_proba = pipe.predict_proba(X_test)[:,1]\n",
    "test_pred  = (test_proba >= best_thresh).astype(int)\n",
    "\n",
    "print(classification_report(y_test, test_pred))\n",
    "print(\"PR‑AUC:\", average_precision_score(y_test, test_proba))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', clf)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#Hyperparameter tuning via GridSearchCV.\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\n",
    "print(\"Best ROC-AUC score from GridSearchCV:\", grid_search.best_score_)\n",
    "\n",
    "#Use the best estimator for evaluation\n",
    "model = grid_search.best_estimator_\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR‑AUC (5‑fold): 0.7181013600048745\n"
     ]
    }
   ],
   "source": [
    "#Verify PR-AUC score is accurate\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "proba_cv = cross_val_predict(pipe, X, y, cv=cv,\n",
    "                             method='predict_proba', n_jobs=-1)[:, 1]\n",
    "\n",
    "print(\"PR‑AUC (5‑fold):\", average_precision_score(y, proba_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best model to *all* contacts who donated < $10\n",
    "candidates = df[df['TOTAL_DONATION_AMOUNT'] < 10].copy()\n",
    "proba = pipe.predict_proba(candidates.drop(columns=all_target_and_leakage_cols))[:,1]\n",
    "candidates['top_donor_score'] = proba\n",
    "ranked = candidates.sort_values('top_donor_score', ascending=False)\n",
    "\n",
    "# Give fund‑raisers an easy export\n",
    "ranked[['CONTACT_ID', 'NAME', 'top_donor_score', 'NET_WORTH',\n",
    "        'TOTAL_EVENTS_LAST_YEAR', 'PRIMARY_RESEARCH_AREA']\n",
    "       ].head(1000).to_csv('high_potential_donors.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part __: Identifying Potential Top Donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top potential donors from contacts with low donation history:\n",
      "   predicted_top_donor_score  TOTAL_DONATION_AMOUNT  NET_WORTH  \\\n",
      "0                     0.4175                   0.41    1171043   \n",
      "1                     0.4075                   0.94   14622726   \n",
      "2                     0.4050                   0.49    1240590   \n",
      "3                     0.3975                   2.45    1721973   \n",
      "4                     0.3950                   0.03    2377305   \n",
      "5                     0.3900                   0.14    1280342   \n",
      "6                     0.3875                   5.80    1328029   \n",
      "7                     0.3850                   0.02    1109344   \n",
      "8                     0.3825                   0.52    1124716   \n",
      "9                     0.3800                   0.00    1186787   \n",
      "\n",
      "   TOTAL_EVENTS_LY                              PRIMARY_RESEARCH_AREA  \n",
      "0                0                                           Genetics  \n",
      "1                0                                       Cell Biology  \n",
      "2                0                                            Unknown  \n",
      "3                0                                            Unknown  \n",
      "4                0                                            Unknown  \n",
      "5                1                                            Unknown  \n",
      "6                0                     Radiation Science and Medicine  \n",
      "7                0                                          Pathology  \n",
      "8                0  Bioinformatics, Computational Biology, and Dat...  \n",
      "9                0                                            Unknown  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# 1)  Pull the \"low donors\" population\n",
    "# -------------------------------------------------------\n",
    "donation_threshold = 10          # ← adjust if needed\n",
    "low_donors = df[df['TOTAL_DONATION_AMOUNT'] < donation_threshold].copy()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2)  Keep exactly the columns the pipeline expects\n",
    "#     (everything except target + leakage + any drops)\n",
    "# -------------------------------------------------------\n",
    "feature_cols = pipe.named_steps['preprocessor'].feature_names_in_\n",
    "X_low_donors = low_donors[feature_cols]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3)  Score the contacts\n",
    "# -------------------------------------------------------\n",
    "low_donors['predicted_top_donor_score'] = pipe.predict_proba(X_low_donors)[:, 1]\n",
    "\n",
    "low_donors['predicted_top_donor_flag'] = (\n",
    "        low_donors['predicted_top_donor_score'] >= best_thresh).astype(int)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4)  Rank the list for fund‑raisers\n",
    "# -------------------------------------------------------\n",
    "potential_donors = (\n",
    "    low_donors\n",
    "      .sort_values('predicted_top_donor_score', ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nTop potential donors from contacts with low donation history:\")\n",
    "display_cols = [\n",
    "    'predicted_top_donor_score',    # model score\n",
    "    'TOTAL_DONATION_AMOUNT',        # current giving\n",
    "    'NET_WORTH',                    # example context fields\n",
    "    'TOTAL_EVENTS_LY',\n",
    "    'PRIMARY_RESEARCH_AREA'\n",
    "]\n",
    "print(potential_donors[display_cols].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 8: Conclusion and Next Steps\n",
    "# ---------------------------\n",
    "# The script above demonstrates:\n",
    "# 1. Data preprocessing including handling missing values, encoding, and scaling.\n",
    "# 2. Splitting your data into training and test sets.\n",
    "# 3. Building a predictive model with hyperparameter tuning.\n",
    "# 4. Evaluating the model's performance using several metrics.\n",
    "# 5. Using the model to identify contacts who look like top donors but have donated little.\n",
    "#\n",
    "# Next steps could include:\n",
    "# - Further feature engineering and exploration (e.g., clustering analysis on high-probability candidates).\n",
    "# - Testing additional models and ensemble methods.\n",
    "# - Validating the model’s predictions with domain experts and iterating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Step 2: Define Target --------\n",
    "donation_cutoff = df[\"TOTAL_DONATION_AMOUNT\"].quantile(0.90)\n",
    "df[\"top_donor\"] = (df[\"TOTAL_DONATION_AMOUNT\"] >= donation_cutoff).astype(int)\n",
    "\n",
    "# -------- Step 3: Feature Engineering --------\n",
    "df[\"DONATION_QUARTILE\"] = pd.cut(\n",
    "    df[\"TOTAL_DONATION_AMOUNT\"],\n",
    "    bins=[-1, 0, 100, 1000, df[\"TOTAL_DONATION_AMOUNT\"].max()],\n",
    "    labels=[0, 1, 2, 3]  # You can relabel these too\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DONATION_QUARTILE\n",
       "0    56244\n",
       "1    22854\n",
       "2     5480\n",
       "3      795\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"DONATION_QUARTILE\"].describe()\n",
    "df[\"DONATION_QUARTILE\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Step 2: Define Target --------\n",
    "donation_cutoff = df[\"TOTAL_DONATION_AMOUNT\"].quantile(0.90)\n",
    "df[\"top_donor\"] = (df[\"TOTAL_DONATION_AMOUNT\"] >= donation_cutoff).astype(int)\n",
    "\n",
    "# -------- Step 3: Feature Engineering --------\n",
    "df[\"donation_bucket\"] = pd.qcut(df[\"TOTAL_DONATION_AMOUNT\"], q=5,\n",
    "                                 labels=[\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"])\n",
    "\n",
    "# -------- Step 4: Handle Nulls --------\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col != \"top_donor\"]\n",
    "\n",
    "df[categorical_cols] = df[categorical_cols].fillna(\"No Answer\")\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n",
    "\n",
    "# -------- Step 5: Feature Importance --------\n",
    "le = LabelEncoder()\n",
    "X_cat = df[categorical_cols].apply(lambda col: le.fit_transform(col.astype(str)))\n",
    "chi2_vals, p_vals = chi2(X_cat, df[\"top_donor\"])\n",
    "chi2_scores = pd.DataFrame({\n",
    "    \"Feature\": categorical_cols,\n",
    "    \"Importance\": chi2_vals,\n",
    "    \"p_value\": p_vals,\n",
    "    \"Method\": \"Chi2\"\n",
    "})\n",
    "\n",
    "X_num = df[numerical_cols]\n",
    "mi_scores = mutual_info_classif(X_num, df[\"top_donor\"])\n",
    "mi_df = pd.DataFrame({\n",
    "    \"Feature\": numerical_cols,\n",
    "    \"Importance\": mi_scores,\n",
    "    \"Method\": \"Mutual_Info\"\n",
    "})\n",
    "\n",
    "# -------- Step 6: Correlation Heatmap --------\n",
    "corr_matrix = df[numerical_cols + [\"top_donor\"]].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# -------- Step 7: Combine Feature Scores --------\n",
    "feature_scores = pd.concat([chi2_scores, mi_df])\n",
    "feature_scores = feature_scores.sort_values(\"Importance\", ascending=False)\n",
    "print(\"\\nTop Features (Pre-Model):\")\n",
    "print(feature_scores.head(10))\n",
    "\n",
    "# -------- Step 8: Prepare Data for Modeling --------\n",
    "X = pd.get_dummies(df.drop(columns=[\"top_donor\", \"Unnamed: 0\"]), drop_first=True)\n",
    "y = df[\"top_donor\"]\n",
    "X = X.fillna(0)\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# -------- Step 9: Train/Test Split --------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------- Step 10: Train Model --------\n",
    "model = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# -------- Step 11: Evaluate --------\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# -------- Step 12: Feature Importance Plot --------\n",
    "model_feature_importance = pd.Series(model.feature_importances_, index=X.columns)\n",
    "model_top_features = model_feature_importance.sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop Features (Model-Based):\")\n",
    "print(model_top_features)\n",
    "\n",
    "model_top_features.plot(kind=\"barh\", title=\"Top 10 Features (Random Forest)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
