{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c501e1d",
   "metadata": {},
   "source": [
    "# SciBERT Topic Classification Pipeline\n",
    "This notebook sets up a standard local environment for fine-tuning SciBERT to classify scientific abstracts by topic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd45f8",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "Install necessary packages. Run this in your terminal or add `!` to run in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb3d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers datasets torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd64e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers tokenizers huggingface-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a2bf2",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59c6fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import inspect\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset #seamless integration with PyTorch/Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline, BertTokenizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a90935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.51.3\n",
      "TrainingArguments class: <class 'transformers.training_args.TrainingArguments'>\n",
      "Defined in module: transformers.training_args\n",
      "Signature: (self, output_dir: Optional[str] = None, overwrite_output_dir: bool = False, do_train: bool = False, do_eval: bool = False, do_predict: bool = False, eval_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'no', prediction_loss_only: bool = False, per_device_train_batch_size: int = 8, per_device_eval_batch_size: int = 8, per_gpu_train_batch_size: Optional[int] = None, per_gpu_eval_batch_size: Optional[int] = None, gradient_accumulation_steps: int = 1, eval_accumulation_steps: Optional[int] = None, eval_delay: Optional[float] = 0, torch_empty_cache_steps: Optional[int] = None, learning_rate: float = 5e-05, weight_decay: float = 0.0, adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-08, max_grad_norm: float = 1.0, num_train_epochs: float = 3.0, max_steps: int = -1, lr_scheduler_type: Union[transformers.trainer_utils.SchedulerType, str] = 'linear', lr_scheduler_kwargs: Union[dict, str, NoneType] = <factory>, warmup_ratio: float = 0.0, warmup_steps: int = 0, log_level: Optional[str] = 'passive', log_level_replica: Optional[str] = 'warning', log_on_each_node: bool = True, logging_dir: Optional[str] = None, logging_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'steps', logging_first_step: bool = False, logging_steps: float = 500, logging_nan_inf_filter: bool = True, save_strategy: Union[transformers.trainer_utils.SaveStrategy, str] = 'steps', save_steps: float = 500, save_total_limit: Optional[int] = None, save_safetensors: Optional[bool] = True, save_on_each_node: bool = False, save_only_model: bool = False, restore_callback_states_from_checkpoint: bool = False, no_cuda: bool = False, use_cpu: bool = False, use_mps_device: bool = False, seed: int = 42, data_seed: Optional[int] = None, jit_mode_eval: bool = False, use_ipex: bool = False, bf16: bool = False, fp16: bool = False, fp16_opt_level: str = 'O1', half_precision_backend: str = 'auto', bf16_full_eval: bool = False, fp16_full_eval: bool = False, tf32: Optional[bool] = None, local_rank: int = -1, ddp_backend: Optional[str] = None, tpu_num_cores: Optional[int] = None, tpu_metrics_debug: bool = False, debug: Union[str, list[transformers.debug_utils.DebugOption]] = '', dataloader_drop_last: bool = False, eval_steps: Optional[float] = None, dataloader_num_workers: int = 0, dataloader_prefetch_factor: Optional[int] = None, past_index: int = -1, run_name: Optional[str] = None, disable_tqdm: Optional[bool] = None, remove_unused_columns: Optional[bool] = True, label_names: Optional[list[str]] = None, load_best_model_at_end: Optional[bool] = False, metric_for_best_model: Optional[str] = None, greater_is_better: Optional[bool] = None, ignore_data_skip: bool = False, fsdp: Union[list[transformers.trainer_utils.FSDPOption], str, NoneType] = '', fsdp_min_num_params: int = 0, fsdp_config: Union[dict, str, NoneType] = None, tp_size: Optional[int] = 0, fsdp_transformer_layer_cls_to_wrap: Optional[str] = None, accelerator_config: Union[dict, str, NoneType] = None, deepspeed: Union[dict, str, NoneType] = None, label_smoothing_factor: float = 0.0, optim: Union[transformers.training_args.OptimizerNames, str] = 'adamw_torch', optim_args: Optional[str] = None, adafactor: bool = False, group_by_length: bool = False, length_column_name: Optional[str] = 'length', report_to: Union[NoneType, str, list[str]] = None, ddp_find_unused_parameters: Optional[bool] = None, ddp_bucket_cap_mb: Optional[int] = None, ddp_broadcast_buffers: Optional[bool] = None, dataloader_pin_memory: bool = True, dataloader_persistent_workers: bool = False, skip_memory_metrics: bool = True, use_legacy_prediction_loop: bool = False, push_to_hub: bool = False, resume_from_checkpoint: Optional[str] = None, hub_model_id: Optional[str] = None, hub_strategy: Union[transformers.trainer_utils.HubStrategy, str] = 'every_save', hub_token: Optional[str] = None, hub_private_repo: Optional[bool] = None, hub_always_push: bool = False, gradient_checkpointing: bool = False, gradient_checkpointing_kwargs: Union[dict, str, NoneType] = None, include_inputs_for_metrics: bool = False, include_for_metrics: list[str] = <factory>, eval_do_concat_batches: bool = True, fp16_backend: str = 'auto', push_to_hub_model_id: Optional[str] = None, push_to_hub_organization: Optional[str] = None, push_to_hub_token: Optional[str] = None, mp_parameters: str = '', auto_find_batch_size: bool = False, full_determinism: bool = False, torchdynamo: Optional[str] = None, ray_scope: Optional[str] = 'last', ddp_timeout: Optional[int] = 1800, torch_compile: bool = False, torch_compile_backend: Optional[str] = None, torch_compile_mode: Optional[str] = None, include_tokens_per_second: Optional[bool] = False, include_num_input_tokens_seen: Optional[bool] = False, neftune_noise_alpha: Optional[float] = None, optim_target_modules: Union[NoneType, str, list[str]] = None, batch_eval_metrics: bool = False, eval_on_start: bool = False, use_liger_kernel: Optional[bool] = False, eval_use_gather_object: Optional[bool] = False, average_tokens_across_devices: Optional[bool] = False) -> None\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"TrainingArguments class:\", TrainingArguments)\n",
    "print(\"Defined in module:\", TrainingArguments.__module__)\n",
    "print(\"Signature:\", inspect.signature(TrainingArguments.__init__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81353756",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\maxwell.bicking\\texts.csv\")  # Update path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc1c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting to class labels: 100%|██████████| 6529/6529 [00:00<00:00, 91734.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the raw strings\n",
    "ds = Dataset.from_pandas(df[['TEXT_CONTENT', 'TOPIC_NEW']])\n",
    "\n",
    "# 2. Convert TOPIC_NEW → ClassLabel, creating a new column \"labels\"\n",
    "ds = ds.class_encode_column('TOPIC_NEW').rename_column('TOPIC_NEW','labels')\n",
    "\n",
    "# 3. Do a stratified split on the ClassLabel\n",
    "ds = ds.train_test_split(test_size=0.2, stratify_by_column='labels')\n",
    "\n",
    "train_ds = ds['train']\n",
    "val_ds   = ds['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95cb25",
   "metadata": {},
   "source": [
    "## 4. Load SciBERT Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eed464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'allenai/scibert_scivocab_uncased'\n",
    "NUM_LABELS  = train_ds.features['labels'].num_classes\n",
    "LABEL_NAMES = train_ds.features['labels'].names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046bbdaa",
   "metadata": {},
   "source": [
    "First clone the scibert github repo to use locally (if using VPN)\n",
    "\n",
    "**git lfs install** <br>\n",
    "**git clone https://huggingface.co/allenai/scibert_scivocab_uncased [insert your path here after the space]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5223a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\maxwell.bicking\\scibert_local and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "'''\n",
    "\n",
    "LOCAL = r\"C:\\Users\\maxwell.bicking\\scibert_local\"\n",
    "tokenizer = BertTokenizer.from_pretrained(LOCAL, do_lower_case=True)\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(\n",
    "    LOCAL,\n",
    "    num_labels=NUM_LABELS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8b3c6",
   "metadata": {},
   "source": [
    "## 5. Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34daa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5223/5223 [00:38<00:00, 135.74 examples/s]\n",
      "Map: 100%|██████████| 1306/1306 [00:09<00:00, 138.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nold\\n\\ndef tokenize_fn(batch):\\n    return tokenizer(\\n        batch['ABSTRACT_CONTENT'],\\n        padding='max_length',\\n        truncation=True,\\n        max_length=512\\n    )\\n\\ntrain_tok = train_ds.map(tokenize_fn, batched=True)\\nval_tok = val_ds.map(tokenize_fn, batched=True)\\ntrain_tok = train_tok.rename_column('label_id', 'labels')\\nval_tok = val_tok.rename_column('label_id', 'labels')\\ntrain_tok.set_format('torch', columns=['input_ids','attention_mask','labels'])\\nval_tok.set_format('torch', columns=['input_ids','attention_mask','labels'])\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"TEXT_CONTENT\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "# Map and remove the raw text column afterwards\n",
    "train_tok = train_ds.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=[\"TEXT_CONTENT\"]\n",
    ")\n",
    "val_tok = val_ds.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=[\"TEXT_CONTENT\"]\n",
    ")\n",
    "\n",
    "# Now we should have: ['labels','input_ids','token_type_ids','attention_mask']\n",
    "print(train_tok.column_names)\n",
    "\n",
    "# Tell the datasets to return PyTorch tensors for these three columns:\n",
    "train_tok.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_tok.set_format  (\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "'''\n",
    "old\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch['TEXT_CONTENT'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_tok = train_ds.map(tokenize_fn, batched=True)\n",
    "val_tok = val_ds.map(tokenize_fn, batched=True)\n",
    "train_tok = train_tok.rename_column('label_id', 'labels')\n",
    "val_tok = val_tok.rename_column('label_id', 'labels')\n",
    "train_tok.set_format('torch', columns=['input_ids','attention_mask','labels'])\n",
    "val_tok.set_format('torch', columns=['input_ids','attention_mask','labels'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab475c81",
   "metadata": {},
   "source": [
    "## 6. Fine-Tuning with Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9e3e0",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Pull representative subsample to use here (locally) and train\n",
    "- Research different fine-tuning options with Azure Foundry\n",
    "- Figure out how deployment works with Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb0004c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD files: ['$ spend Grid.xlsx', '01ae53c7-0004-b5a6-0037-fd070261102e.csv (1).gz', '01ae53c7-0004-b5a6-0037-fd070261102e.csv.gz', '038264fe-bf8d-4723-9edb-19ce3e12c9c1.csv', '06c7bcfbd8ca.csv', '10YearGivingHistory.xlsx', '11-1-2022.csv', '110316112.webp', '1687273277904.xlsx', '1d064a71f2d2.csv', '2004-2005 Program Comm Roster.pdf', '2004-2005 Program Comm Roster.xlsx', '2014-2015 Education Committee Suggested Members_ Alpha Order.csv', '2015 Education Comm Suggestions as of 7.23.14.csv', '2015 Education Committee Member Invitation Tracking Report 9.17.14.csv', '2015 Education Committee Member Invitation Tracking Report 9.3.14.csv', '2015 Education Committee Members - FINAL.csv', '2015 Education Committee Suggested Members_ Approved 8.11.14.csv', '2015 Montly E-Blast Reports.xlsx', '2016-2017 AM Education Committee Roster (Final).csv', '2017 Annual Meeting Education Comm Nominations.csv', '2023 Advances in Kidney Cancer Research.csv', '2023 Meetings & Attendees.xlsx', '2023 Time Card Approval Dates (as of 2-16-2023).pdf', '2024 Pricing Analysis 08 09 2023 (1).xlsx', '2024 RNAs 10-2.csv', '2024-04-25.ics', '20240204_valorem_val_setmb.csv', '20241205_manuscripts_for_LLM_test (1).zip', '20241205_manuscripts_for_LLM_test.zip', '2024SABCS with AACR ID and Mem Type.csv', '2024SABCS with AACR ID.csv', '2024TaxReturn.PDF', '2024_TARMAC_SL8_USER_MANUAL_ENGLISH.pdf', '2025 Invited Speakers Chairs CTI.xlsx', '2025-02-21 2_29pm.csv', '2025-03-31 12_13pm (1).csv', '2025-03-31 12_13pm (2).csv', '2025-03-31 12_13pm (3).csv', '2025-03-31 12_13pm.csv', '2025-04-10 11_08am (1).csv', '2025-04-10 11_08am.csv', '20250418_abstracts.xlsx', '4_Zone.png', '50mileschicagoreport (2).csv', '50mileschicagoreport.csv', '52b99415-f32d-4e9c-b3e7-66ac68345928.csv', '784e6c041272.csv', '7z2301-x64.exe', '980.pdf', 'AACR 2023 Evaluation Form.docx', 'AACR 23 Session IDs.xlsx', 'AACR Cover Letter.docx', 'AACR Data Governance New Country List - FInal 08OCT2024.xlsx', 'AACR Data Governance New Country List, iso, region.xlsx', 'AACR Foundation Community Membership Program Survey(1-1).xlsx', 'AACR Foundation Donor Survey(1-3).xlsx', 'AACR Logo.PNG', 'AACR NON-DISCRIMINATION AND SEXUAL HARASSMENT POLICY 3-6-17.pdf', 'AACR Prod Schema.xlsx', 'AACR Social Media Policy_032023.pdf', 'AACR Theme.json', 'AACR+Annual+Meeting+2023-trackwise (1).zip', 'AACR+Annual+Meeting+2024-trackwise (1).zip', 'AACR+Annual+Meeting+2024-trackwise.zip', 'AACR-SAA Recipients (MASTER).xlsx', 'AACR25_order_1214.csv', 'AACR25_order_745.csv', 'AACR_Annual_Meeting_Schedule_of_Events_01.19.2024.xlsx', 'Achutti Duso-2023.txt', 'ACSST5Y2023.S1901_2025-04-04T133201.zip', 'Adams-2024.txt', 'AdvancOrganSite.zip', 'Ali-2023.txt', 'ALL_PROGRAMS.accdb', 'AM24LiveSessionsAll.xlsx', 'AM24LiveSessionsAllv2.csv', 'AM24LiveSessionsAllv3.xlsx', 'AMLiveSessionsAllv3.xlsx', 'AMRecordedSessionsAllv3.xlsx', 'AMSessionsAllv2RECORDED.csv', 'amy franz thomas resume (1).pdf', 'Anaconda3-2023.03-1-Windows-x86_64.exe', 'Anaconda3-2024.06-1-Windows-x86_64 (1).exe', 'Anaconda3-2024.06-1-Windows-x86_64.exe', 'Annual Meeting Ed Comm_Confirmed 072517 (FINAL).csv', 'Annual Meeting Ed Comm_Confirmed 072517.csv', 'Annual Meeting Ed Comm_Nominations.csv', 'Annual Meeting Education Committee Members_111115.csv', 'Antman_145x145.jpg', 'ap-40480143.pkpass', 'API_SH.XPD.CHEX.GD.ZS_DS2_en_excel_v2_4247 (1).xls', 'API_SH.XPD.CHEX.GD.ZS_DS2_en_excel_v2_4247.xls', 'API_WLD_DS2_en_excel_v2_5458281.xls', 'APRA-tbd--Aug-16-2024.xlsx', 'ARGP Global Impact Tracker.xlsx', 'Athela Villaruel Orientation Schedule.docx', 'Attain-Marketing Cloud Current State Analysis.pdf', 'Attendee (1).zip', 'Attendee.zip', 'AwardsLectures.zip', 'BA Position 151-191.pdf', 'backfill_aacr_ids_04.02.2024.csv', 'backfill_aacr_ids_errors_eps_1529_04.03.2024.csv', 'backfill_aacr_ids_success_issues_eps_1529_04.03.2024.csv', 'backfill_aacr_ids_success_issues_eps_1529_04.05.2024.csv', 'Bicking Maxwell 202312011344460802.pdf', 'blah.ipynb', 'Blair-2023.txt', 'Budget Allocation Method-AACR Customer Buying Power(1-8) (1).xlsx', 'Budget Allocation Method-AACR Customer Buying Power(1-8).xlsx', 'bulkQuery_result_7508W000013mwhxQAA_7518W00001MyIoUQAV_7528W00000gBPyG.csv', 'bulk_print_output_1_29_2025_12_53_PM.pdf', 'bulk_print_output_1_29_2025_12_57_PM.pdf', 'bulk_print_output_1_29_2025_1_01_PM.pdf', 'bulk_print_output_1_29_2025_2_44_PM.pdf', 'Cancer Health Disparities Registration Budget.xlsx', 'cancersurveillance-599ed-export.csv', 'cancersurveillance-599ed-export.json', 'cancersurveillance-599ed-export.xlsx', 'cancer_research_trends_gnn.ipynb', 'CareerDev.zip', 'Car_sales.csv', 'Celik-2023.txt', 'ChatGPT Image Apr 3, 2025, 01_38_26 PM.png', 'chunk_metadata.jsonl', 'CLASS.xlsx', 'ClinicalPlenary.zip', 'ClinicalTrials.zip', 'Co-op Intern - Athela Villaruel_ September 24_ 2024 to March 28_ 2025.msg', 'committees-pdf-to-csv.ipynb', 'CompletedPAResidencyCertification.pdf', 'COMPUTE WH SCHEMATA.xlsx', 'Contact Snapshots.ipynb', 'ContactsforIDRwith10Contacts.xlsx', 'contacts_for_donor_propensity.csv', 'contact_snapshot_parquets-20241219T184414Z-001.zip', 'contact_snapshot_parquets-20241219T184414Z-002.zip', 'Coop Candidates for Interview.pdf', 'Coop resumes Spring cycle.pdf', 'Copy of 04. MONSTER LIST (1).xlsx', 'Copy of 04. MONSTER LIST.xlsx', 'Copy of 2023 Health Disparities User Seg-2023-06-13-15-28-13.xlsx', 'Copy of 2023 Health Disparities User Seg-2023-07-14-13-37-02.xlsx', 'Copy of 2023 Health Disparities User Seg-2023-07-19-14-28-12.xlsx', 'Copy of 2023 Health Disparities User Seg-2023-07-21-13-45-24.xlsx', 'Copy of 2023 Health Disparities User Seg-2023-08-17-10-05-59.xlsx', 'Copy of Annual Meeting Ed Comm_Nominations.csv', 'Copy of Work Group report-2025-01-21-10-42-24.xlsx', 'Countries External w Price Rules (1).pdf', 'Countries External w Price Rules.pdf', 'Countries Internal.pdf', 'Countries New Categories Final.pdf', 'Countries New Categories Final.xlsx', 'Country Income Classifications (1).xlsx', 'Country Income Classifications.xlsx', 'Cover Letter Max Bicking.pdf', 'Cover-Letter[7300].pdf', 'Crimes_-_2022.csv', 'CSI MOLECULAR TARGETS 2019 TARGT19_order_150303.xlsx', 'CTI Notes for AM Reporting (1).docx', 'CTI Notes for AM Reporting.docx', 'Current Year Membership (1).xlsx', 'Current Year Membership.xlsx', 'curroncol-18-00708.pdf', 'Customer Identity Test (1).csv', 'Customer Identity Test.csv', 'Customer Service Report - CSI.csv', 'Customer Service Report - CSI.pdf', 'd64ec1225df24b0dcec68b5750568d8a_54805b47-10c4-49d8-bdc0-75dc32aeea61_1440x.progressive.jpg', 'd77316d0-9f3a-42aa-8109-7ef8d441cb2a.csv', 'data (1).xlsx', 'data (2).xlsx', 'data (21).xlsx', 'data (3).xlsx', 'data (4).xlsx', 'data (5).xlsx', 'data (6).xlsx', 'data (7).xlsx', 'data (8).xlsx', 'Data Analyst Job Description_7.24.docx', 'data.csv', 'data.xlsx', 'DataMart - Source to Target Mapping - MEETING_REGISTRATION (1).xlsx', 'DataMart - Source to Target Mapping - MEETING_REGISTRATION.xlsx', 'db2a3fdb-d53b-443b-ba1c-56dc1d704ebb.csv', 'ddewd.csv', 'defaaafe-6ebf-438d-959c-8e7ea77e2984.csv', 'desktop.ini', 'diad-instructor-english (1).zip', 'diad-instructor-english.zip', 'diad-student-english.zip', 'DiagnosticsThera.zip', 'Digitize Committee Files 2.ipynb', 'Digitize Committee Files.ipynb', 'Disparities.zip', 'Distinct Degrees List.csv', 'distinct_topics_categorized.csv', 'distinct_topics_categorized_v2.csv', 'DLCOA.pdf', 'donation_data.csv', 'donor_propensity_sample.csv', 'dotNetFx35setup (1).exe', 'dotNetFx35setup.exe', 'Drexel Coop Job Description.docx', 'drive-download-20241107T150451Z-001', 'drive-download-20241107T150451Z-001.zip', 'drive-download-20241107T153334Z-001.zip', 'Drug and Alcohol-Free Workplace Program 3-6-17.pdf', 'DuplicateEmails.xlsx', 'Eblast_HR_23AM_CareerFair_ReserveSpace_570x340_2206012B_1.jpg', 'Educational.zip', 'embedding_retrieved_chunks1 (1).txt', 'embedding_retrieved_chunks1 (2).txt', 'embedding_retrieved_chunks1 (3).txt', 'embedding_retrieved_chunks1.txt', 'Emergency Text Notification Policy & Guidelines 3-6-2017 (1).pdf', 'Emergency Text Notification Policy & Guidelines 3-6-2017 (2).pdf', 'Emergency Text Notification Policy & Guidelines 3-6-2017.pdf', 'f6755583-b28e-4e72-a080-178cfc8ea41c_i-ZwMHn7n-X4.jpg', 'FB Copy of EconSimulationNEW-draft.xlsx', 'FDA Approvals.pbix', 'Fellows ALL.xlsx', 'FileZilla_3.66.5_win64-setup.exe', 'FileZilla_3.67.0_win64-setup.exe', 'FileZilla_3.67.1_win64-setup.exe', 'FileZilla_3.68.1_win64-setup.exe', 'finalapi.csv.zip', 'final_summary.txt', 'Fonteva Account to NPC Account Validation.xlsx', 'Fonteva Contact to NPC Account Validation Results.csv', 'Forum.zip', 'Foundation Volunteer Inquiries.csv', 'Fwd_ From Cadence Cycling (1).eml', 'Fwd_ From Cadence Cycling.eml', 'Generative-AI-and-LLMs-for-Dummies.pdf', 'GENIE LLM Combined Approach.docx', 'GENIE_Chunks (1).csv', 'GENIE_Chunks (2).csv', 'GENIE_Chunks (3).csv', 'GENIE_Chunks (4).csv', 'GENIE_Chunks.csv', 'GENIE_Chunks_Summarized_Part1.csv', 'GENIE_LLM_lit_review.pptx', 'GENIE_Summary_Colab_Notebook.ipynb', 'geocoded_addresses.csv', 'geocoded_addresses2.csv', 'geocoded_addresses3.csv', 'geocoded_addresses_final.csv', 'Git-2.42.0.2-64-bit.exe', 'Grantee List.xlsx', 'Hematology filter revised-December 2024 (1).docx', 'Historical Committee Members - Annual Meeting.xlsx', 'HistoricAMDataMasterFile.xlsx', 'How pharma can accelerate business impact from advanced analytics _ McKinsey.pdf', 'Ikram-2024.pdf', 'image (1).png', 'image.png', 'IMG_0015.jpg', 'IMG_0063.PNG', 'IMG_0177.HEIC', 'IMG_0180.HEIC', 'IMG_0961.png', 'IMG_1599.heic', 'IMG_20241115_130043.jpg', 'IMG_8155.jpg', 'IMG_8221.HEIC', 'IMG_8305.jpg', 'IMG_8689.HEIC', 'IMG_9122 (1).png', 'IMG_9122.png', 'IMG_9822.PNG', 'IMG_9825.PNG', 'iMIS detail and activtiy tabs.docx', 'iMIS detail and activtiy tabs.pdf', 'incidents_part1_part2.csv', 'inputprep', 'Instructor (1).zip', 'Instructor (2).zip', 'Instructor (3).zip', 'Instructor.zip', 'insurance_agent_clustering_pipeline.ipynb', 'Interview Questions.docx', 'invited speaker view.xlsx', 'Invoice.pdf', 'ISO Codes.xlsx', 'JTorres Movie Slide.png', 'JudgeReport-4-15-2025 (1).csv', 'JudgeReport-4-15-2025 (2).csv', 'JudgeReport-4-16-2025.csv', 'LiveAttuploadv0.csv', 'MajorSymp.zip', 'matrix.csv', 'Maxwell_Bicking_CL.docx', 'Maxwell_Bicking_Resume.docx', 'Maxwell_Bicking_Resume.pdf', 'MBicking AACR 2023 Evaluation Form Self.docx', 'mbickingpass312.jpg', 'MeetExpert.zip', 'Member term Data.sql', 'Membership Overview.xlsx', 'membership_data1.csv', 'Membership_Flat_File-2024-08-02-09-07-35.xlsx', 'Membership_Flat_File-2024-08-02-09-28-56.xlsx', 'Membership_Flat_File-2024-08-09-09-26-56.xlsx', 'MemFlatFile.csv', 'memover.csv', 'MemOverviewExport.csv', 'Methods.zip', 'Microsoft Copilot Overview.docx', 'Microsoft Pilot research new.docx', 'Migration Validation (1).sql', 'Migration Validation.sql', 'MiniSymp2.zip', 'movie_report (1).pbix', 'movie_report.pbix', 'movie_report.pbix.zip', 'MV5BNDcxMTZjOTQtMTM4ZS00ZWMyLTg0MTQtZmEyOTRmMTE5NWIyXkEyXkFqcGdeQXVyMzE5MDUxODM@._V1_.jpg', \"MY22_ROVAL_WHEELSETS_OWNER'S_MANUAL_ENGLISH (1).pdf\", \"MY22_ROVAL_WHEELSETS_OWNER'S_MANUAL_ENGLISH.pdf\", 'Nathan Cover Letter.pdf', 'NCI-NIH.zip', 'NetFxRepairTool.exe', 'NHA indicators (1).xlsx', 'NHA indicators.xlsx', 'Nominations Selected_FINAL LIST TO BE INVITED 080416.csv', 'noun-human-resources-199769.png', 'npp.8.5.6.Installer.x64.exe', 'OfficeSetup.exe', 'OneDrive_1_6-22-2023.zip', 'OneDrive_2024-12-11.zip', 'OneDrive_2024-12-20.zip', 'OnVUE-23.12.33.exe', 'OnVUE-23.14.56.exe', 'OnVUE-23.15.45.exe', 'output.csv', 'output.png', 'PAResidencyCertification.pdf', 'PBIDataSetMaster.xlsx', 'PBIDesktopSetup_x64 (1).exe', 'PBIDesktopSetup_x64 (10).exe', 'PBIDesktopSetup_x64 (11).exe', 'PBIDesktopSetup_x64 (12).exe', 'PBIDesktopSetup_x64 (13).exe', 'PBIDesktopSetup_x64 (14).exe', 'PBIDesktopSetup_x64 (15).exe', 'PBIDesktopSetup_x64 (2).exe', 'PBIDesktopSetup_x64 (3).exe', 'PBIDesktopSetup_x64 (4).exe', 'PBIDesktopSetup_x64 (5).exe', 'PBIDesktopSetup_x64 (6).exe', 'PBIDesktopSetup_x64 (7).exe', 'PBIDesktopSetup_x64 (8).exe', 'PBIDesktopSetup_x64 (9).exe', 'PBIDesktopSetup_x64.exe', 'pic1.jpg', 'pic2.jpg', 'pic3.jpg', 'Pics for Headshot-20250413T175157Z-001.zip', 'Plenary2.zip', 'png-clipart-computer-icons-business-management-others-service-business.png', 'PopulationSci.zip', 'Post-award Grantee Tracking Chart.xlsx', 'Postman-win64-Setup.exe', 'PowerBIMembershipReport.xlsx', 'power_app_prem.png', 'Preeti_Ladwa_Resume.pdf', 'Prepare for GSO presentation .msg', 'PreventionResearch.zip', 'primary research area list.csv', 'ProposalCentralExport-DataDictionary-2023-10-24.xlsx', 'Proposed Economic Classifications.xlsx', 'python-3.11.3-amd64.exe', 'QAT-299 Notes.xlsx', 'query (1).iqy', 'query (2).iqy', 'query.iqy', 'Quickhelp Power BI.docx', 'README.md', 'reclassified_topics.csv', 'Reclassified_Topics_Corrected.csv', 'Regional Sales Sample (1).pbix', 'Regional Sales Sample.pbix', 'report1692056563436SALESFORCEAM2021Reg.xlsx', 'report1737474628892.xls', 'report1738788460105.csv', 'report1740753634284.xls', 'research areas list.csv', 'Resume- Jesenia Torres-1121.pdf', 'SABCS Full Registration List 11-24-24 (1).xlsx', 'SABCS Full Registration List 11-24-24.xlsx', 'SABCS2024 (1).xlsx', 'SABCS2024.xlsx', 'scibert_classifier.ipynb', 'SentinelInstaller_windows_64bit_v21_7_7_40005.msi', 'Session Attendance v2.ipynb', 'Set Up Memo for Co-op Intern Athela Villaruel, 9-24-2024 to 3-28-2025.docx', 'SlackSetup (1).exe', 'SlackSetup.exe', 'slime.ipynb', 'Software & Network Usage Code of Ethics 3-6-17.pdf', 'Source to Target Mapping (1).xlsx', 'Source to Target Mapping.xlsx', 'Speaker Demographics Contact Table.xlsx', 'SpecialSess.zip', 'sql-course-materials (1).zip', 'sql-course-materials.zip', 'SQL2022-SSEI-Expr (1).exe', 'SQL2022-SSEI-Expr.exe', 'SSMS-Setup-ENU (1).exe', 'SSMS-Setup-ENU (2).exe', 'SSMS-Setup-ENU (3).exe', 'SSMS-Setup-ENU.exe', 'Starter Report (Single Page) (1).pbix', 'Starter Report (Single Page) (2).pbix', 'Starter Report (Single Page) (3).pbix', 'Starter Report (Single Page).pbix', 'Store Sales.pbix', 'summaries.xlsx', 'taxii-v2.1-os.docx', 'Taylor plus 1 .zwo', 'The Wheels on the Bus_V1.pdf', 'TOTAL (Paid + Comp) 10.25.21-2024-10-10-14-14-58.xlsx', 'Tree_runks.webp', 'US Zip Codes from 2013 Government Data.csv', 'vo_data_24.csv', 'VRCOA.pdf', 'VSCodeUserSetup-x64-1.78.2.exe', 'w2-2024.pdf', 'WGKenan.csv', 'wgreport.csv', 'WHO-CHE data.xlsx', 'Working Group Information for IT.xlsx', 'world_bank_sf_metadata_07.16.2024.xlsx', 'yf476hg', 'Zoom_cm_frsbu5xs8ezsursZ9vvrZo4_m1QVw68+5AoYv-TpCu03H9YlbKRZznOZGAeV+@bfyX3mDVF6iTwCYT_ke7cc1c3e434e44f5_.exe', 'Zou-2024.pdf', '[COMPLETE] Source to Target Mapping CTI to DW (4).xlsx', '[IMPLEMENTED] Datamart - Speakers STM.xlsx', '[TEMPLATE] DataMart STM.xlsx', '[TEMPLATE] Source to Target Mapping.xlsx', '~$2024 Pricing Analysis 08 09 2023 (1).xlsx', '~$hela Villaruel Orientation Schedule.docx', '~$Historical Committee Members - Annual Meeting.xlsx', '~$Proposed Economic Classifications.xlsx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"CWD files:\", os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad8b7e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maxwell.bicking\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\maxwell.bicking\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\maxwell.bicking\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maxwell.bicking\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'c:\\Users\\maxwell.bicking\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e54d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./scibert-finetuned',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1'\n",
    ")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(p.label_ids, preds),\n",
    "        'f1': f1_score(p.label_ids, preds, average='macro')\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model (or last checkpoint)\n",
    "trainer.save_model(\"./scibert-finetuned/final_model\")\n",
    "\n",
    "# also save the tokenizer\n",
    "tokenizer.save_pretrained(\"./scibert-finetuned/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f584e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall the model later\n",
    "\n",
    "MODEL_DIR = \"./scibert-finetuned/final_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9992b9",
   "metadata": {},
   "source": [
    "## 7. Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(eval_dataset=val_tok)\n",
    "print(metrics)\n",
    "\n",
    "pred_output = trainer.predict(test_dataset=val_tok)\n",
    "preds = np.argmax(pred_output.predictions, axis=1)\n",
    "labels = pred_output.label_ids\n",
    "print(classification_report(labels, preds, target_names=le.classes_))\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ccad7",
   "metadata": {},
   "source": [
    "## 8. Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f07fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    'text-classification',\n",
    "    model=trainer.state.best_model_checkpoint,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "def classify_abstract(text):\n",
    "    res = classifier(text)[0]\n",
    "    top = max(res, key=lambda x: x['score'])\n",
    "    return le.inverse_transform([int(top['label'])])[0], top['score']\n",
    "\n",
    "# Example Usage\n",
    "example = \"Sample abstract text here\"\n",
    "print(classify_abstract(example))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
