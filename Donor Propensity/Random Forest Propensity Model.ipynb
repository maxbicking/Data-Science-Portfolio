{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donor Propensity Model\n",
    "\n",
    "This notebook uses a Random Forest Classifier to find individuals who have a high potential to donate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_df = pd.read_csv(r\"C:\\Users\\maxwell.bicking\\donation_data_syn.csv\")\n",
    "\n",
    "#import median income by zip code data from Census Bureau\n",
    "census_df = pd.read_csv(r\"C:\\Users\\maxwell.bicking\\data-science-portfolio\\Donor Propensity\\Median Income by ZIP.csv\")\n",
    "\n",
    "census_df['ZIP'] = census_df['Geographic Area Name'].str.strip().str[-5:] #add zip column to join to contact table\n",
    "\n",
    "df = contacts_df.merge(\n",
    "    census_df[['ZIP', 'Median Income']],\n",
    "    left_on='ZIP_CODE',\n",
    "    right_on='ZIP',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df = df.drop(columns=['ZIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>EMAIL_OPT_OUT</th>\n",
       "      <th>CALL_OPT_OUT</th>\n",
       "      <th>DAYS_SINCE_CREATED</th>\n",
       "      <th>DAYS_SINCE_MODIFIED</th>\n",
       "      <th>DAYS_SINCE_LAST_ACTIVITY</th>\n",
       "      <th>HOME_CALL_OPT_OUT</th>\n",
       "      <th>MOBILE_CALL_OPT_OUT</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_DONATION_AMOUNT</th>\n",
       "      <th>TOTAL_DONATIONS</th>\n",
       "      <th>TOTAL_DONATION_AMOUNT_LY</th>\n",
       "      <th>TOTAL_DONATIONS_LY</th>\n",
       "      <th>ASSOCIATED_WITH_MEMBERSHIP</th>\n",
       "      <th>TITLE_CHANGE</th>\n",
       "      <th>PUSHED</th>\n",
       "      <th>CHURNED</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>Median Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2314</td>\n",
       "      <td>54</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>41.70</td>\n",
       "      <td>3</td>\n",
       "      <td>4.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92130</td>\n",
       "      <td>201731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2326</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2381</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21201</td>\n",
       "      <td>44722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>665</td>\n",
       "      <td>57</td>\n",
       "      <td>714.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33612</td>\n",
       "      <td>43919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>27</td>\n",
       "      <td>281.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46202</td>\n",
       "      <td>61082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>United States</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2301</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2312</td>\n",
       "      <td>57</td>\n",
       "      <td>666.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60612</td>\n",
       "      <td>60457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2025</td>\n",
       "      <td>50</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92115</td>\n",
       "      <td>75178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2333</td>\n",
       "      <td>40</td>\n",
       "      <td>196.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92130</td>\n",
       "      <td>201731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2239</td>\n",
       "      <td>31</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30322</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        COUNTRY   AGE  EMAIL_OPT_OUT  CALL_OPT_OUT  \\\n",
       "0           0  United States   NaN           True         False   \n",
       "1           1  United States   NaN           True         False   \n",
       "2           2  United States   NaN           True         False   \n",
       "3           3  United States   NaN           True         False   \n",
       "4           4  United States   NaN           True         False   \n",
       "5           5  United States  30.0           True         False   \n",
       "6           6            NaN   NaN           True         False   \n",
       "7           7  United States   NaN           True         False   \n",
       "8           8  United States   NaN           True         False   \n",
       "9           9  United States   NaN           True         False   \n",
       "\n",
       "   DAYS_SINCE_CREATED  DAYS_SINCE_MODIFIED  DAYS_SINCE_LAST_ACTIVITY  \\\n",
       "0                2314                   54                    1331.0   \n",
       "1                2326                   34                       NaN   \n",
       "2                2381                   96                       NaN   \n",
       "3                 665                   57                     714.0   \n",
       "4                2020                   27                     281.0   \n",
       "5                2301                   36                       NaN   \n",
       "6                2312                   57                     666.0   \n",
       "7                2025                   50                    1238.0   \n",
       "8                2333                   40                     196.0   \n",
       "9                2239                   31                    1272.0   \n",
       "\n",
       "   HOME_CALL_OPT_OUT  MOBILE_CALL_OPT_OUT  ...  TOTAL_DONATION_AMOUNT  \\\n",
       "0              False                False  ...                  41.70   \n",
       "1              False                False  ...                   0.03   \n",
       "2              False                False  ...                   3.22   \n",
       "3              False                False  ...                   0.00   \n",
       "4              False                False  ...                   0.00   \n",
       "5              False                False  ...                   0.00   \n",
       "6              False                False  ...                   0.00   \n",
       "7              False                False  ...                   0.05   \n",
       "8              False                False  ...                   0.00   \n",
       "9              False                False  ...                   0.00   \n",
       "\n",
       "   TOTAL_DONATIONS  TOTAL_DONATION_AMOUNT_LY  TOTAL_DONATIONS_LY  \\\n",
       "0                3                      4.15                   1   \n",
       "1                1                      1.28                   1   \n",
       "2                2                      3.80                   1   \n",
       "3                0                      0.28                   1   \n",
       "4                0                      0.00                   1   \n",
       "5                1                      0.00                   1   \n",
       "6                1                      0.01                   1   \n",
       "7                1                      0.00                   1   \n",
       "8                0                      4.26                   1   \n",
       "9                1                      0.00                   1   \n",
       "\n",
       "   ASSOCIATED_WITH_MEMBERSHIP TITLE_CHANGE PUSHED  CHURNED ZIP_CODE  \\\n",
       "0                           0            0      0        0    92130   \n",
       "1                           0            0      0        0    27157   \n",
       "2                           0            0      1        0    21201   \n",
       "3                           1            0      0        0    33612   \n",
       "4                           0            0      0        0    46202   \n",
       "5                           0            0      0        0    40536   \n",
       "6                           0            0      0        0    60612   \n",
       "7                           0            0      0        0    92115   \n",
       "8                           0            0      0        1    92130   \n",
       "9                           0            1      0        0    30322   \n",
       "\n",
       "  Median Income  \n",
       "0        201731  \n",
       "1           NaN  \n",
       "2         44722  \n",
       "3         43919  \n",
       "4         61082  \n",
       "5           NaN  \n",
       "6         60457  \n",
       "7         75178  \n",
       "8        201731  \n",
       "9           NaN  \n",
       "\n",
       "[10 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxwell.bicking\\AppData\\Local\\Temp\\ipykernel_29448\\3556697819.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"HIGHEST_DEGREE\", \"POLITICAL_PARTY\"]].fillna(\"Unknown\", inplace = True)\n",
      "C:\\Users\\maxwell.bicking\\AppData\\Local\\Temp\\ipykernel_29448\\3556697819.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['MEMBER_TYPE', 'MEMBERSHIP_STATUS']].fillna(\"Nonmember\", inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df[[\"GENDER\", \"RACE\", \"COUNTRY\", \"ZIP_CODE\", \n",
    "    \"INCOME_LEVEL\", \"INSTITUTION_TYPE\", \"PRIMARY_RESEARCH_AREA\", \n",
    "    \"HIGHEST_DEGREE\", \"POLITICAL_PARTY\"]].fillna(\"Unknown\", inplace = True)\n",
    "\n",
    "df[['MEMBER_TYPE', 'MEMBERSHIP_STATUS']].fillna(\"Nonmember\", inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "df[\"NET_WORTH_QUARTILE\"] = pd.qcut(df[\"NET_WORTH\"], q=4, labels=[1, 2, 3, 4])\n",
    "df[\"NET_WORTH_QUARTILE\"] = df[\"NET_WORTH_QUARTILE\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "\n",
    "- Ensure TOTAL_DONATION_AMOUNT exists\n",
    "- Nulls:\n",
    "- Gender, race, country, zip, Income level, institution type, primary research area, highest degree, political party -> unknown\n",
    "- Member type, mem status -> nonmember\n",
    " \n",
    "- Tons of DAYS_SINCE columns to worry about, will fill with max vals\n",
    "\n",
    "SUGGESTED COLUMNS:\n",
    "- Total number of donations\n",
    "- First gift amount\n",
    "- Time since first gift\n",
    "- Net worth (or wealth score)\n",
    "- Event attendance\n",
    "- Engagement metrics (volunteer, emails, etc.)\n",
    "\n",
    "df[\"donation_growth_rate\"] = df[\"total_donated_last_2y\"] / df[\"total_donated_first_2y\"]\n",
    "\n",
    "Add binary column \"has donated in the last year\"\n",
    "\n",
    "Add binary column \"is top donor\" for total >$10,000\n",
    "\n",
    "Add HAS_MADE_LARGE_DONATION and/or LARGEST_DONATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 2: Data Preprocessing\n",
    "# ---------------------------\n",
    "#Define the target column and determine feature columns.\n",
    "#We predict \"top_donor\" (assumed to be 0/1 or similar).\n",
    "target_column = 'top_donor'\n",
    "\n",
    "#Remove the target column from the list of features.\n",
    "#We might choose to drop columns that are not predictive or have too many unique values (e.g., MAILING_ZIP_CODE)\n",
    "drop_columns = ['MAILING_ZIP_CODE']  #add others if needed\n",
    "\n",
    "#Separate features and target\n",
    "X = df.drop(columns=[target_column] + drop_columns)\n",
    "y = df[target_column]\n",
    "\n",
    "#Identify lists for categorical and numerical columns.\n",
    "categorical_cols = [\n",
    "    'MAILING_COUNTRY', 'GENDER', 'INCOME_LEVEL', 'INSTITUTION_TYPE', \n",
    "    'MEMBER_TYPE', 'MEMBERSHIP_STATUS', 'PRIMARY_RESEARCH_AREA',\n",
    "    'RACE', 'POLITICAL_PARTY', 'HIGHEST_DEGREE', 'Median Income'\n",
    "]\n",
    "\n",
    "# The remaining columns (or explicitly defined ones) are numerical or boolean.\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "#If there are boolean columns in categorical_cols, they may be left as numerical.\n",
    "#make sure data types are correct:\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'bool':\n",
    "        X[col] = X[col].astype(int)\n",
    "\n",
    "# Fill missing values.\n",
    "# For numerical features, we can fill with the median.\n",
    "# For categorical features, fill with a constant such as 'missing'.\n",
    "for col in numerical_cols:\n",
    "    X[col].fillna(X[col].median(), inplace=True)\n",
    "for col in categorical_cols:\n",
    "    X[col].fillna('missing', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 3: Building a Preprocessing Pipeline\n",
    "# ---------------------------\n",
    "# We will create a ColumnTransformer that:\n",
    "# - One-hot encodes categorical columns.\n",
    "# - Scales numerical columns.\n",
    "# You may decide to do additional feature engineering on high cardinality columns.\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Splitting Data into Training and Test Sets\n",
    "# ---------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 5: Building and Training the Predictive Model\n",
    "# ---------------------------\n",
    "# We create a pipeline that performs the preprocessing then fits a Random Forest classifier.\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Optionally, you can do hyperparameter tuning via GridSearchCV.\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\n",
    "print(\"Best ROC-AUC score from GridSearchCV:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best estimator for evaluation\n",
    "model = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 6: Model Evaluation\n",
    "# ---------------------------\n",
    "# Evaluate on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"ROC-AUC score:\", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 7: Identifying Potential Donors with Limited Donation History\n",
    "# ---------------------------\n",
    "# In this section, we want to identify contacts who have not yet donated or have donated very little,\n",
    "# but whose attributes are similar to our top donors.\n",
    "#\n",
    "# Here, we assume that \"TOTAL_DONATION_AMOUNT\" is available in the original DataFrame.\n",
    "# Define a threshold below which you consider a donation as minimal.\n",
    "donation_threshold = 10  # Adjust the threshold as appropriate (for example, $10)\n",
    "\n",
    "# Identify contacts who have given little or nothing (you might also want to consider using MOST_RECENT_DONATION_AMOUNT)\n",
    "low_donors = df[df['TOTAL_DONATION_AMOUNT'] < donation_threshold].copy()\n",
    "\n",
    "# Ensure all required features are processed similarly to X.\n",
    "# Note: low_donors should include all the features needed for the model.\n",
    "X_low_donors = low_donors.drop(columns=[target_column] + drop_columns)\n",
    "\n",
    "# Fill missing values in the low_donors set as was done in preprocessing.\n",
    "for col in numerical_cols:\n",
    "    if col in X_low_donors.columns:\n",
    "        X_low_donors[col].fillna(X_low_donors[col].median(), inplace=True)\n",
    "for col in categorical_cols:\n",
    "    if col in X_low_donors.columns:\n",
    "        X_low_donors[col].fillna('missing', inplace=True)\n",
    "\n",
    "# Convert booleans to integers (if not already handled)\n",
    "for col in X_low_donors.columns:\n",
    "    if X_low_donors[col].dtype == 'bool':\n",
    "        X_low_donors[col] = X_low_donors[col].astype(int)\n",
    "\n",
    "# Generate predicted probabilities for these contacts.\n",
    "low_donors_probs = model.predict_proba(X_low_donors)[:, 1]\n",
    "\n",
    "# Append the predicted probabilities to the low_donors DataFrame for ranking.\n",
    "low_donors['predicted_top_donor_score'] = low_donors_probs\n",
    "\n",
    "# Sort contacts by predicted probability of being a top donor (descending order).\n",
    "potential_donors = low_donors.sort_values(by='predicted_top_donor_score', ascending=False)\n",
    "\n",
    "print(\"\\nTop potential donors from contacts with low donation history:\")\n",
    "print(potential_donors[['predicted_top_donor_score', 'TOTAL_DONATION_AMOUNT']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 8: Conclusion and Next Steps\n",
    "# ---------------------------\n",
    "# The script above demonstrates:\n",
    "# 1. Data preprocessing including handling missing values, encoding, and scaling.\n",
    "# 2. Splitting your data into training and test sets.\n",
    "# 3. Building a predictive model with hyperparameter tuning.\n",
    "# 4. Evaluating the model's performance using several metrics.\n",
    "# 5. Using the model to identify contacts who look like top donors but have donated little.\n",
    "#\n",
    "# Next steps could include:\n",
    "# - Further feature engineering and exploration (e.g., clustering analysis on high-probability candidates).\n",
    "# - Testing additional models and ensemble methods.\n",
    "# - Validating the model’s predictions with domain experts and iterating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Step 2: Define Target --------\n",
    "donation_cutoff = df[\"TOTAL_DONATION_AMOUNT\"].quantile(0.90)\n",
    "df[\"top_donor\"] = (df[\"TOTAL_DONATION_AMOUNT\"] >= donation_cutoff).astype(int)\n",
    "\n",
    "# -------- Step 3: Feature Engineering --------\n",
    "df[\"DONATION_QUARTILE\"] = pd.cut(\n",
    "    df[\"TOTAL_DONATION_AMOUNT\"],\n",
    "    bins=[-1, 0, 100, 1000, df[\"TOTAL_DONATION_AMOUNT\"].max()],\n",
    "    labels=[0, 1, 2, 3]  # You can relabel these too\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DONATION_QUARTILE\n",
       "0    56244\n",
       "1    22854\n",
       "2     5480\n",
       "3      795\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"DONATION_QUARTILE\"].describe()\n",
    "df[\"DONATION_QUARTILE\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Step 2: Define Target --------\n",
    "donation_cutoff = df[\"TOTAL_DONATION_AMOUNT\"].quantile(0.90)\n",
    "df[\"top_donor\"] = (df[\"TOTAL_DONATION_AMOUNT\"] >= donation_cutoff).astype(int)\n",
    "\n",
    "# -------- Step 3: Feature Engineering --------\n",
    "df[\"donation_bucket\"] = pd.qcut(df[\"TOTAL_DONATION_AMOUNT\"], q=5,\n",
    "                                 labels=[\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"])\n",
    "\n",
    "# -------- Step 4: Handle Nulls --------\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col != \"top_donor\"]\n",
    "\n",
    "df[categorical_cols] = df[categorical_cols].fillna(\"No Answer\")\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n",
    "\n",
    "# -------- Step 5: Feature Importance --------\n",
    "le = LabelEncoder()\n",
    "X_cat = df[categorical_cols].apply(lambda col: le.fit_transform(col.astype(str)))\n",
    "chi2_vals, p_vals = chi2(X_cat, df[\"top_donor\"])\n",
    "chi2_scores = pd.DataFrame({\n",
    "    \"Feature\": categorical_cols,\n",
    "    \"Importance\": chi2_vals,\n",
    "    \"p_value\": p_vals,\n",
    "    \"Method\": \"Chi2\"\n",
    "})\n",
    "\n",
    "X_num = df[numerical_cols]\n",
    "mi_scores = mutual_info_classif(X_num, df[\"top_donor\"])\n",
    "mi_df = pd.DataFrame({\n",
    "    \"Feature\": numerical_cols,\n",
    "    \"Importance\": mi_scores,\n",
    "    \"Method\": \"Mutual_Info\"\n",
    "})\n",
    "\n",
    "# -------- Step 6: Correlation Heatmap --------\n",
    "corr_matrix = df[numerical_cols + [\"top_donor\"]].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# -------- Step 7: Combine Feature Scores --------\n",
    "feature_scores = pd.concat([chi2_scores, mi_df])\n",
    "feature_scores = feature_scores.sort_values(\"Importance\", ascending=False)\n",
    "print(\"\\nTop Features (Pre-Model):\")\n",
    "print(feature_scores.head(10))\n",
    "\n",
    "# -------- Step 8: Prepare Data for Modeling --------\n",
    "X = pd.get_dummies(df.drop(columns=[\"top_donor\", \"Unnamed: 0\"]), drop_first=True)\n",
    "y = df[\"top_donor\"]\n",
    "X = X.fillna(0)\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# -------- Step 9: Train/Test Split --------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------- Step 10: Train Model --------\n",
    "model = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# -------- Step 11: Evaluate --------\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# -------- Step 12: Feature Importance Plot --------\n",
    "model_feature_importance = pd.Series(model.feature_importances_, index=X.columns)\n",
    "model_top_features = model_feature_importance.sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop Features (Model-Based):\")\n",
    "print(model_top_features)\n",
    "\n",
    "model_top_features.plot(kind=\"barh\", title=\"Top 10 Features (Random Forest)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
